{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/qq_31367861/article/details/111145816?spm=5176.12282029.0.0.24ac6e12RdK2dO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用其方法仅对其中的两万条数据进行复现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比赛链接：https://tianchi.aliyun.com/competition/entrance/531830/information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import multiprocessing\n",
    "from collections import Counter\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import entropy\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import datetime\n",
    "import time\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/senlinlidewo/pyprogram/天池竞赛-零基础金融风控/数据/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(DATA_PATH):\n",
    "    train_label = pd.read_csv(DATA_PATH + 'train.csv')['isDefault']\n",
    "    train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "    test = pd.read_csv(DATA_PATH + 'testA.csv')\n",
    "    feats = [f for f in train.columns if f not in ['isDefault']]\n",
    "    # train = train[feats]\n",
    "    test = test[feats]\n",
    "    print('train.shape', train.shape)\n",
    "    print('test.shape', test.shape)\n",
    "\n",
    "    return train_label, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape (800000, 47)\n",
      "test.shape (200000, 46)\n"
     ]
    }
   ],
   "source": [
    "train_label, train, test = load_dataset(DATA_PATH=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train1 = pd.read_csv('/Users/senlinlidewo/pyprogram/天池竞赛-零基础金融风控/数据/train.csv')\n",
    "test1 = pd.read_csv('/Users/senlinlidewo/pyprogram/天池竞赛-零基础金融风控/数据/testA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 47)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sample(20000)\n",
    "test = test.sample(10000)\n",
    "train.shape\n",
    "#这个sample每次运行都会发生改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n11</th>\n",
       "      <td>1759</td>\n",
       "      <td>8.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employmentLength</th>\n",
       "      <td>1134</td>\n",
       "      <td>5.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n7</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n1</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n2</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n3</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n5</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n6</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n14</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n8</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n12</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n13</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n0</th>\n",
       "      <td>1047</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n4</th>\n",
       "      <td>857</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10</th>\n",
       "      <td>857</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revolUtil</th>\n",
       "      <td>14</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubRecBankruptcies</th>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>5</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postCode</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinquency_2years</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interestRate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subGrade</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employmentTitle</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homeOwnership</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annualIncome</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verificationStatus</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issueDate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isDefault</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionCode</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ficoRangeLow</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policyCode</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliesCreditLine</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicationType</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initialListStatus</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalAcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revolBal</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loanAmnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubRec</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openAcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ficoRangeHigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Total  Percent\n",
       "n11                  1759     8.80\n",
       "employmentLength     1134     5.67\n",
       "n7                   1047     5.24\n",
       "n1                   1047     5.24\n",
       "n2                   1047     5.24\n",
       "n3                   1047     5.24\n",
       "n5                   1047     5.24\n",
       "n6                   1047     5.24\n",
       "n14                  1047     5.24\n",
       "n8                   1047     5.24\n",
       "n9                   1047     5.24\n",
       "n12                  1047     5.24\n",
       "n13                  1047     5.24\n",
       "n0                   1047     5.24\n",
       "n4                    857     4.28\n",
       "n10                   857     4.28\n",
       "revolUtil              14     0.07\n",
       "pubRecBankruptcies     10     0.05\n",
       "dti                     5     0.02\n",
       "postCode                1     0.00\n",
       "delinquency_2years      0     0.00\n",
       "term                    0     0.00\n",
       "interestRate            0     0.00\n",
       "installment             0     0.00\n",
       "grade                   0     0.00\n",
       "subGrade                0     0.00\n",
       "employmentTitle         0     0.00\n",
       "homeOwnership           0     0.00\n",
       "annualIncome            0     0.00\n",
       "verificationStatus      0     0.00\n",
       "issueDate               0     0.00\n",
       "isDefault               0     0.00\n",
       "purpose                 0     0.00\n",
       "regionCode              0     0.00\n",
       "ficoRangeLow            0     0.00\n",
       "policyCode              0     0.00\n",
       "title                   0     0.00\n",
       "earliesCreditLine       0     0.00\n",
       "applicationType         0     0.00\n",
       "initialListStatus       0     0.00\n",
       "totalAcc                0     0.00\n",
       "revolBal                0     0.00\n",
       "loanAmnt                0     0.00\n",
       "pubRec                  0     0.00\n",
       "openAcc                 0     0.00\n",
       "ficoRangeHigh           0     0.00\n",
       "id                      0     0.00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如何确认哪些列含有缺失值？\n",
    "def missing_percentage(df):\n",
    "    \"\"\"This function takes a DataFrame(df) as input and returns two columns, total missing values and total missing values percentage\"\"\"\n",
    "    total = df.isnull().sum().sort_values(ascending = False)\n",
    "    percent = round(df.isnull().sum().sort_values(ascending = False)/len(df)*100,2)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total','Percent'])\n",
    "missing_value_percent = missing_percentage(train)\n",
    "missing_value_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n11',\n",
       " 'employmentLength',\n",
       " 'n7',\n",
       " 'n1',\n",
       " 'n2',\n",
       " 'n3',\n",
       " 'n5',\n",
       " 'n6',\n",
       " 'n14',\n",
       " 'n8',\n",
       " 'n9',\n",
       " 'n12',\n",
       " 'n13',\n",
       " 'n0',\n",
       " 'n4',\n",
       " 'n10',\n",
       " 'revolUtil',\n",
       " 'pubRecBankruptcies',\n",
       " 'dti']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = missing_value_percent.index[missing_value_percent.Percent>0]\n",
    "list(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    train[col].fillna(r'\\N', inplace=True)\n",
    "cols = [f for f in cols if f not in ['employmentLength']]\n",
    "for col in cols:\n",
    "    train[col].replace({r'\\N': -999}, inplace=True)\n",
    "    train[col] = train[col]\n",
    "#先把所有的空缺值填为/N，然后employmentLength列保持不变，其他的空缺值由/n变为-999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>postCode</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revolBal</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalAcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initialListStatus</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicationType</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliesCreditLine</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policyCode</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revolUtil</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubRecBankruptcies</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loanAmnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubRec</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interestRate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subGrade</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employmentTitle</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employmentLength</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homeOwnership</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annualIncome</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verificationStatus</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issueDate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isDefault</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionCode</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinquency_2years</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ficoRangeLow</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ficoRangeHigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openAcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Total  Percent\n",
       "postCode                1      0.0\n",
       "id                      0      0.0\n",
       "revolBal                0      0.0\n",
       "totalAcc                0      0.0\n",
       "initialListStatus       0      0.0\n",
       "applicationType         0      0.0\n",
       "earliesCreditLine       0      0.0\n",
       "title                   0      0.0\n",
       "policyCode              0      0.0\n",
       "n0                      0      0.0\n",
       "n1                      0      0.0\n",
       "n2                      0      0.0\n",
       "n3                      0      0.0\n",
       "n4                      0      0.0\n",
       "n5                      0      0.0\n",
       "n6                      0      0.0\n",
       "n7                      0      0.0\n",
       "n8                      0      0.0\n",
       "n9                      0      0.0\n",
       "n10                     0      0.0\n",
       "n11                     0      0.0\n",
       "n12                     0      0.0\n",
       "n13                     0      0.0\n",
       "revolUtil               0      0.0\n",
       "pubRecBankruptcies      0      0.0\n",
       "loanAmnt                0      0.0\n",
       "pubRec                  0      0.0\n",
       "term                    0      0.0\n",
       "interestRate            0      0.0\n",
       "installment             0      0.0\n",
       "grade                   0      0.0\n",
       "subGrade                0      0.0\n",
       "employmentTitle         0      0.0\n",
       "employmentLength        0      0.0\n",
       "homeOwnership           0      0.0\n",
       "annualIncome            0      0.0\n",
       "verificationStatus      0      0.0\n",
       "issueDate               0      0.0\n",
       "isDefault               0      0.0\n",
       "purpose                 0      0.0\n",
       "regionCode              0      0.0\n",
       "dti                     0      0.0\n",
       "delinquency_2years      0      0.0\n",
       "ficoRangeLow            0      0.0\n",
       "ficoRangeHigh           0      0.0\n",
       "openAcc                 0      0.0\n",
       "n14                     0      0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>6617</td>\n",
       "      <td>33.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1868</td>\n",
       "      <td>9.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>1569</td>\n",
       "      <td>7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1527</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1310</td>\n",
       "      <td>6.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>1242</td>\n",
       "      <td>6.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1220</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-999.0</th>\n",
       "      <td>1155</td>\n",
       "      <td>5.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>925</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>915</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>875</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>777</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Total  Percent\n",
       " 12.0    6617    33.08\n",
       " 2.0     1868     9.34\n",
       " 0.5     1569     7.85\n",
       " 3.0     1527     7.64\n",
       " 1.0     1310     6.55\n",
       " 5.0     1242     6.21\n",
       " 4.0     1220     6.10\n",
       "-999.0   1155     5.78\n",
       " 6.0      925     4.62\n",
       " 7.0      915     4.58\n",
       " 8.0      875     4.38\n",
       " 9.0      777     3.88"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#我想知道employlength里面的数据种类\n",
    "def percent_value_counts(df, feature):\n",
    "    \"\"\"This function takes in a dataframe and a column and finds the percentage of the value_counts\"\"\"\n",
    "    percent = pd.DataFrame(round(df.loc[:,feature].value_counts(dropna=False, normalize=True)*100,2))\n",
    "    ## creating a df with th\n",
    "    total = pd.DataFrame(df.loc[:,feature].value_counts(dropna=False))\n",
    "    ## concating percent and total dataframe\n",
    "\n",
    "    total.columns = [\"Total\"]\n",
    "    percent.columns = ['Percent']\n",
    "    return pd.concat([total, percent], axis = 1)\n",
    "percent_value_counts(train,'employmentLength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def employmentLength_deal(x):\n",
    "    if x == r'\\N':\n",
    "        result = -999\n",
    "    elif x == -999:\n",
    "        result = -999\n",
    "    elif x == '-999':\n",
    "        result = -999\n",
    "    elif x == '< 1 year':\n",
    "        result = 0.5\n",
    "    elif x == '10+ years':\n",
    "        result = 12\n",
    "    else:\n",
    "        result = int(x.split(' ')[0][0])\n",
    "    # print(result)\n",
    "    return result\n",
    "train['employmentLength'] = train['employmentLength'].apply(lambda x: employmentLength_deal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade', 'subGrade', 'employmentLength', 'issueDate', 'earliesCreditLine']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成分类变量list\n",
    "train_object = list(train.select_dtypes(include = ['object']))\n",
    "train_object\n",
    "# 这样有一定的风险，比如postcode是多分类变量而其类型是float。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 无序变量容易被默认为numberic    'postCode', 'purpose', 'regionCode', 'homeOwnership', 'employmentTitle','title'\n",
    "# 有序多分类变量   'grade', 'subGrade'\n",
    "# object但是是连续变量 'issueDate', 'earliesCreditLine' 'employmentLength'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meancode 编码无序变量 \n",
    "#平均编码类定义\n",
    "class MeanEncoder:\n",
    "    def __init__(self, categorical_features, n_splits=5, target_type='classification', prior_weight_func=None):\n",
    "        \"\"\"\n",
    "        :param categorical_features: list of str, the name of the categorical columns to encode\n",
    "\n",
    "        :param n_splits: the number of splits used in mean encoding\n",
    "\n",
    "        :param target_type: str, 'regression' or 'classification'\n",
    "\n",
    "        :param prior_weight_func:\n",
    "        a function that takes in the number of observations, and outputs prior weight\n",
    "        when a dict is passed, the default exponential decay function will be used:\n",
    "        k: the number of observations needed for the posterior to be weighted equally as the prior\n",
    "        f: larger f --> smaller slope\n",
    "        \"\"\"\n",
    "\n",
    "        self.categorical_features = categorical_features\n",
    "        self.n_splits = n_splits\n",
    "        self.learned_stats = {}\n",
    "\n",
    "        if target_type == 'classification':\n",
    "            self.target_type = target_type\n",
    "            self.target_values = []\n",
    "        else:\n",
    "            self.target_type = 'regression'\n",
    "            self.target_values = None\n",
    "\n",
    "        if isinstance(prior_weight_func, dict):\n",
    "            self.prior_weight_func = eval('lambda x: 1 / (1 + np.exp((x - k) / f))', dict(prior_weight_func, np=np))\n",
    "        elif callable(prior_weight_func):\n",
    "            self.prior_weight_func = prior_weight_func\n",
    "        else:\n",
    "            self.prior_weight_func = lambda x: 1 / (1 + np.exp((x - 2) / 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_encode_subroutine(X_train, y_train, X_test, variable, target, prior_weight_func):\n",
    "        X_train = X_train[[variable]].copy()\n",
    "        X_test = X_test[[variable]].copy()\n",
    "\n",
    "        if target is not None:\n",
    "            nf_name = '{}_pred_{}'.format(variable, target)\n",
    "            X_train['pred_temp'] = (y_train == target).astype(int)  # classification\n",
    "        else:\n",
    "            nf_name = '{}_pred'.format(variable)\n",
    "            X_train['pred_temp'] = y_train  # regression\n",
    "        prior = X_train['pred_temp'].mean()\n",
    "\n",
    "        col_avg_y = X_train.groupby(by=variable, axis=0)['pred_temp'].agg([('mean','mean'), ('beta','size')])\n",
    "        col_avg_y['beta'] = prior_weight_func(col_avg_y['beta'])\n",
    "        col_avg_y[nf_name] = col_avg_y['beta'] * prior + (1 - col_avg_y['beta']) * col_avg_y['mean']\n",
    "        col_avg_y.drop(['beta', 'mean'], axis=1, inplace=True)\n",
    "\n",
    "        nf_train = X_train.join(col_avg_y, on=variable)[nf_name].values\n",
    "        nf_test = X_test.join(col_avg_y, on=variable).fillna(prior, inplace=False)[nf_name].values\n",
    "\n",
    "        return nf_train, nf_test, prior, col_avg_y\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :param y: pandas Series or numpy array, n_samples\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        if self.target_type == 'classification':\n",
    "            skf = StratifiedKFold(self.n_splits)\n",
    "        else:\n",
    "            skf = KFold(self.n_splits)\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            self.target_values = sorted(set(y))\n",
    "            self.learned_stats = {'{}_pred_{}'.format(variable, target): [] for variable, target in\n",
    "                                  product(self.categorical_features, self.target_values)}\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, target,\n",
    "                        self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        else:\n",
    "            self.learned_stats = {'{}_pred'.format(variable): [] for variable in self.categorical_features}\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, None,\n",
    "                        self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        return X_new\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "        else:\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['postCode', 'purpose', 'regionCode', 'homeOwnership', 'employmentTitle','title']\n",
    "MeanEnocodeFeature = class_list  # 声明需要平均数编码的特征\n",
    "ME = MeanEncoder(MeanEnocodeFeature, target_type='classification')\n",
    "train = ME.transform(train) \n",
    "# 声明平均数编码的类\n",
    "##这个MeanEncoder是怎么调用的？调用前后数据集发生了什么变化呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对有序分类进行处理\n",
    "\n",
    "def gradeTrans(x):\n",
    "    dict = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7}\n",
    "    result = dict[x]\n",
    "    return result\n",
    "\n",
    "\n",
    "def subGradeTrans(x):\n",
    "    dict = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7}\n",
    "    result = dict[x[0]]\n",
    "    result = result * 5 + int(x[1])\n",
    "    return result\n",
    "    \n",
    "train['grade'] = train['grade'].apply(lambda x: gradeTrans(x))\n",
    "train['subGrade'] = train['subGrade'].apply(lambda x: subGradeTrans(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cols = ['issueDate', 'earliesCreditLine']\n",
    "for col in cols:\n",
    "    print(train[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col in cols:\n",
    "    train[col] = pd.to_datetime(train[col])\n",
    "    train[col] = train[col].map(lambda x: x.year)\n",
    "#dataframe apply函数\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def earliesCreditLine_month_deal(x):\n",
    "    x = x.split('-')[0]\n",
    "    # print(x)\n",
    "    dict = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10,\n",
    "            'Nov': 11, 'Dec': 12}\n",
    "    result = dict[x]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['avg_income'] = data['annualIncome'] / data['employmentLength']\n",
    "data['total_income'] = data['annualIncome'] * data['employmentLength']\n",
    "data['avg_loanAmnt'] = data['loanAmnt'] / data['term']\n",
    "data['mean_interestRate'] = data['interestRate'] / data['term']\n",
    "data['all_installment'] = data['installment'] * data['term']\n",
    "\n",
    "data['rest_money_rate'] = data['avg_loanAmnt'] / (data['annualIncome'] + 0.1)  # 287个收入为0\n",
    "data['rest_money'] = data['annualIncome'] - data['avg_loanAmnt']\n",
    "\n",
    "data['closeAcc'] = data['totalAcc'] - data['openAcc']\n",
    "\n",
    "data['rest_pubRec'] = data['pubRec'] - data['pubRecBankruptcies']\n",
    "\n",
    "data['rest_Revol'] = data['loanAmnt'] - data['revolBal']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['earliesCreditLine_year'] = data['earliesCreditLine'].apply(lambda x: 2020 - (int(x.split('-')[-1])))\n",
    "data['earliesCreditLine_month'] = data['earliesCreditLine'].apply(lambda x: earliesCreditLine_month_deal(x))\n",
    "data['earliesCreditLine_Allmonth'] = data['earliesCreditLine_year'] * 12 - data['earliesCreditLine_month']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##交叉特征\n",
    "from tqdm import tqdm\n",
    "col_cat = ['subGrade', 'grade', 'employmentLength', 'term', 'homeOwnership', 'postCode', 'regionCode','employmentTitle','title']\n",
    "col_num = ['dti', 'revolBal','revolUtil', 'interestRate', 'loanAmnt', 'installment', 'annualIncome', 'n14',\n",
    "             'n2', 'n6', 'n9', 'n5', 'n8']\n",
    "             \n",
    "# 定义离散型特征和连续型特征交叉特征统计函数\n",
    "def cross_cat_num(df, num_col, cat_col):\n",
    "    for f1 in tqdm(cat_col):\n",
    "        g = df.groupby(f1, as_index=False)\n",
    "        for f2 in tqdm(num_col):\n",
    "            feat = g[f2].agg({\n",
    "                '{}_{}_max'.format(f1, f2): 'max', '{}_{}_min'.format(f1, f2): 'min',\n",
    "                '{}_{}_median'.format(f1, f2): 'median',\n",
    "            })\n",
    "            df = df.merge(feat, on=f1, how='left')\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      " 23%|██▎       | 3/13 [00:00<00:00, 24.14it/s]\u001b[A\n",
      " 54%|█████▍    | 7/13 [00:00<00:00, 30.07it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:00<00:00, 31.12it/s]\u001b[A\n",
      " 11%|█         | 1/9 [00:00<00:03,  2.38it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      " 31%|███       | 4/13 [00:00<00:00, 33.58it/s]\u001b[A\n",
      " 62%|██████▏   | 8/13 [00:00<00:00, 32.10it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:00<00:00, 30.98it/s]\u001b[A\n",
      " 22%|██▏       | 2/9 [00:00<00:02,  2.37it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      " 23%|██▎       | 3/13 [00:00<00:00, 26.46it/s]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:00<00:00, 25.03it/s]\u001b[A\n",
      " 69%|██████▉   | 9/13 [00:00<00:00, 25.41it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:00<00:00, 24.63it/s]\u001b[A\n",
      " 33%|███▎      | 3/9 [00:01<00:02,  2.12it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      " 23%|██▎       | 3/13 [00:00<00:00, 23.90it/s]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:00<00:00, 23.54it/s]\u001b[A\n",
      " 69%|██████▉   | 9/13 [00:00<00:00, 23.43it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:00<00:00, 23.02it/s]\u001b[A\n",
      " 44%|████▍     | 4/9 [00:01<00:02,  1.96it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      " 23%|██▎       | 3/13 [00:00<00:00, 22.51it/s]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:00<00:00, 21.60it/s]\u001b[A\n",
      " 69%|██████▉   | 9/13 [00:00<00:00, 21.17it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:00<00:00, 20.74it/s]\u001b[A\n",
      " 56%|█████▌    | 5/9 [00:02<00:02,  1.80it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 18.43it/s]\u001b[A\n",
      " 31%|███       | 4/13 [00:00<00:00, 17.90it/s]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:00<00:00, 17.63it/s]\u001b[A\n",
      " 62%|██████▏   | 8/13 [00:00<00:00, 17.54it/s]\u001b[A\n",
      " 77%|███████▋  | 10/13 [00:00<00:00, 17.30it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:00<00:00, 17.29it/s]\u001b[A\n",
      " 67%|██████▋   | 6/9 [00:03<00:01,  1.60it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 17.54it/s]\u001b[A\n",
      " 31%|███       | 4/13 [00:00<00:00, 17.01it/s]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:00<00:00, 16.89it/s]\u001b[A\n",
      " 62%|██████▏   | 8/13 [00:00<00:00, 16.87it/s]\u001b[A\n",
      " 77%|███████▋  | 10/13 [00:00<00:00, 16.78it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:00<00:00, 16.68it/s]\u001b[A\n",
      " 78%|███████▊  | 7/9 [00:04<00:01,  1.48it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 14.84it/s]\u001b[A\n",
      " 31%|███       | 4/13 [00:00<00:00, 14.67it/s]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:00<00:00, 14.65it/s]\u001b[A\n",
      " 62%|██████▏   | 8/13 [00:00<00:00, 14.59it/s]\u001b[A\n",
      " 77%|███████▋  | 10/13 [00:00<00:00, 14.44it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:00<00:00, 14.37it/s]\u001b[A\n",
      " 89%|████████▉ | 8/9 [00:05<00:00,  1.33it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 14.88it/s]\u001b[A\n",
      " 31%|███       | 4/13 [00:00<00:00, 14.24it/s]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:00<00:00, 13.84it/s]\u001b[A\n",
      " 62%|██████▏   | 8/13 [00:00<00:00, 13.50it/s]\u001b[A\n",
      " 77%|███████▋  | 10/13 [00:00<00:00, 13.36it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:00<00:00, 13.46it/s]\u001b[A\n",
      "100%|██████████| 9/9 [00:06<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "data = cross_cat_num(data, col_num, col_cat) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n特征处理后： (20000, 425)\n"
     ]
    }
   ],
   "source": [
    "#暴力特征\n",
    "def myEntro(x):\n",
    "    \"\"\"\n",
    "        calculate shanno ent of x\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    x_value_list = set([x[i] for i in range(x.shape[0])])\n",
    "    ent = 0.0\n",
    "    for x_value in x_value_list:\n",
    "        p = float(x[x == x_value].shape[0]) / x.shape[0]\n",
    "        logp = np.log2(p)\n",
    "        ent -= p * logp\n",
    "    #     print(x_value,p,logp)\n",
    "    # print(ent)\n",
    "    return ent\n",
    "\n",
    "#求均方根\n",
    "def myRms(records):\n",
    "    records = list(records)\n",
    "    \"\"\"\n",
    "    均方根值 反映的是有效值而不是平均值\n",
    "    \"\"\"\n",
    "    return np.math.sqrt(sum([x ** 2 for x in records]) / len(records))\n",
    "\n",
    "\n",
    "def myMode(x):\n",
    "    return np.mean(pd.Series.mode(x))\n",
    "    \n",
    "\n",
    "def myQ25(x):\n",
    "    return x.quantile(0.25)\n",
    "    \n",
    "def myQ75(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "def myQ10(x):\n",
    "    return x.quantile(0.1)\n",
    "    \n",
    "def myQ90(x):\n",
    "    return x.quantile(0.9)\n",
    "    \n",
    "\n",
    "def myRange(x):\n",
    "    return pd.Series.max(x) - pd.Series.min(x)\n",
    "\n",
    "n_feat = ['n0', 'n1', 'n2', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14', ]\n",
    "nameList = ['min', 'max', 'sum', 'mean', 'median', 'skew', 'std', 'mode', 'range', 'Q25','Q75']\n",
    "statList = ['min', 'max', 'sum', 'mean', 'median', 'skew', 'std', myMode, myRange, myQ25, myQ75]\n",
    "\n",
    "for i in range(len(nameList)):\n",
    "\tdata['n_feat_{}'.format(nameList[i])] = data[n_feat].agg(statList[i], axis=1)\n",
    "print('n特征处理后：', data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(folds.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-270d233a48a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(train_data,train_target,test_size = 0.2,random_state=6666)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model(train, target, test, k):\n",
    "\n",
    "    feats = [f for f in train.columns if f not in ['id', 'isDefault']]\n",
    "    feaNum = len(feats)\n",
    "    print('参与训练的特征数目:', len(feats))\n",
    "#     seeds = [6666,2020]\n",
    "    seeds = [2020]\n",
    "    output_preds = 0\n",
    "    xgb_oof_probs = np.zeros(train.shape[0])\n",
    "\n",
    "    for seed in seeds:\n",
    "        folds = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "        oof_probs = np.zeros(train.shape[0])\n",
    "\n",
    "        offline_score = []\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "        params = {'booster': 'gbtree',\n",
    "                  'objective': 'binary:logistic',\n",
    "                  'eval_metric': 'auc',\n",
    "                  'min_child_weight': 5,\n",
    "                  'max_depth': 8,\n",
    "                  'eta': 0.01,\n",
    "                  # 'scale_pos_weight': 0.2,\n",
    "                  'seed': seed,\n",
    "                  'nthread': -1,\n",
    "                  'tree_method': 'gpu_hist'\n",
    "                  }\n",
    "        for i, (train_index, test_index) in enumerate(folds.split(train, target)):\n",
    "            \n",
    "            train_y, test_y = target[train_index], target[test_index]\n",
    "            train_X, test_X = train[feats].iloc[train_index, :], train[feats].iloc[test_index, :]\n",
    "            train_matrix = xgb.DMatrix(train_X, label=train_y, missing=np.nan)\n",
    "            valid_matrix = xgb.DMatrix(test_X, label=test_y, missing=np.nan)\n",
    "            test_matrix = xgb.DMatrix(test[feats], missing=np.nan)\n",
    "            watchlist = [(train_matrix, 'train'), (valid_matrix, 'eval')]\n",
    "            model = xgb.train(params, train_matrix, num_boost_round=30000, evals=watchlist, verbose_eval=100,\n",
    "                              early_stopping_rounds=600)\n",
    "            val_pred = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            train_pred = model.predict(train_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            xgb_oof_probs[test_index] += val_pred / len(seeds)\n",
    "            # oof_probs[test_index] += val_pred\n",
    "            test_pred = model.predict(test_matrix, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "            # 绘制roc曲线\n",
    "            train_auc_value, valid_auc_value = plotroc(train_y, train_pred, test_y, val_pred)\n",
    "            print('train_auc:{},valid_auc{}'.format(train_auc_value, valid_auc_value))\n",
    "            offline_score.append(valid_auc_value)\n",
    "            print(offline_score)\n",
    "            output_preds += test_pred / k / len(seeds)\n",
    "         \n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"Feature\"] = model.get_fscore().keys()\n",
    "            fold_importance_df[\"importance\"] = model.get_fscore().values()\n",
    "            fold_importance_df[\"fold\"] = i + 1\n",
    "\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        print('all_auc:', roc_auc_score(target.values, oof_probs))\n",
    "        print('OOF-MEAN-AUC:%.6f, OOF-STD-AUC:%.6f' % (np.mean(offline_score), np.std(offline_score)))\n",
    "        feature_sorted = feature_importance_df.groupby(['Feature'])['importance'].mean().sort_values(ascending=False)\n",
    "        feature_sorted.to_csv('feature_importance.csv')\n",
    "        top_features = feature_sorted.index\n",
    "        print(feature_importance_df.groupby(['Feature'])['importance'].mean().sort_values(ascending=False).head(50))\n",
    "    return output_preds, xgb_oof_probs, np.mean(offline_score), feaNum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train in module xgboost.training:\n",
      "\n",
      "train(params, dtrain, num_boost_round=10, evals=(), obj=None, feval=None, maximize=None, early_stopping_rounds=None, evals_result=None, verbose_eval=True, xgb_model=None, callbacks=None)\n",
      "    Train a booster with given parameters.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    params : dict\n",
      "        Booster params.\n",
      "    dtrain : DMatrix\n",
      "        Data to be trained.\n",
      "    num_boost_round: int\n",
      "        Number of boosting iterations.\n",
      "    evals: list of pairs (DMatrix, string)\n",
      "        List of validation sets for which metrics will evaluated during training.\n",
      "        Validation metrics will help us track the performance of the model.\n",
      "    obj : function\n",
      "        Customized objective function.\n",
      "    feval : function\n",
      "        Customized evaluation function.\n",
      "    maximize : bool\n",
      "        Whether to maximize feval.\n",
      "    early_stopping_rounds: int\n",
      "        Activates early stopping. Validation metric needs to improve at least once in\n",
      "        every **early_stopping_rounds** round(s) to continue training.\n",
      "        Requires at least one item in **evals**.\n",
      "        The method returns the model from the last iteration (not the best one).\n",
      "        If there's more than one item in **evals**, the last entry will be used\n",
      "        for early stopping.\n",
      "        If there's more than one metric in the **eval_metric** parameter given in\n",
      "        **params**, the last metric will be used for early stopping.\n",
      "        If early stopping occurs, the model will have three additional fields:\n",
      "        ``bst.best_score``, ``bst.best_iteration`` and ``bst.best_ntree_limit``.  Use\n",
      "        ``bst.best_ntree_limit`` to get the correct value if ``num_parallel_tree`` and/or\n",
      "        ``num_class`` appears in the parameters.  ``best_ntree_limit`` is the result of\n",
      "        ``num_parallel_tree * best_iteration``.\n",
      "    evals_result: dict\n",
      "        This dictionary stores the evaluation results of all the items in watchlist.\n",
      "    \n",
      "        Example: with a watchlist containing\n",
      "        ``[(dtest,'eval'), (dtrain,'train')]`` and\n",
      "        a parameter containing ``('eval_metric': 'logloss')``,\n",
      "        the **evals_result** returns\n",
      "    \n",
      "        .. code-block:: python\n",
      "    \n",
      "            {'train': {'logloss': ['0.48253', '0.35953']},\n",
      "             'eval': {'logloss': ['0.480385', '0.357756']}}\n",
      "    \n",
      "    verbose_eval : bool or int\n",
      "        Requires at least one item in **evals**.\n",
      "        If **verbose_eval** is True then the evaluation metric on the validation set is\n",
      "        printed at each boosting stage.\n",
      "        If **verbose_eval** is an integer then the evaluation metric on the validation set\n",
      "        is printed at every given **verbose_eval** boosting stage. The last boosting stage\n",
      "        / the boosting stage found by using **early_stopping_rounds** is also printed.\n",
      "        Example: with ``verbose_eval=4`` and at least one item in **evals**, an evaluation metric\n",
      "        is printed every 4 boosting stages, instead of every boosting stage.\n",
      "    xgb_model : file name of stored xgb model or 'Booster' instance\n",
      "        Xgb model to be loaded before training (allows training continuation).\n",
      "    callbacks : list of callback functions\n",
      "        List of callback functions that are applied at end of each iteration.\n",
      "        It is possible to use predefined callbacks by using\n",
      "        :ref:`Callback API <callback_api>`.\n",
      "        Example:\n",
      "    \n",
      "        .. code-block:: python\n",
      "    \n",
      "            [xgb.callback.reset_learning_rate(custom_rates)]\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Booster : a trained booster model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(xgb.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train\n",
    "target = y_train\n",
    "test = X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参与训练的特征数目: 423\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [20000, 800000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-635e78d044d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_oof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaNum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-2f08b0d44e17>\u001b[0m in \u001b[0;36mxgb_model\u001b[0;34m(train, target, test, k)\u001b[0m\n\u001b[1;32m     26\u001b[0m                   \u001b[0;34m'tree_method'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'gpu_hist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                   }\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[1;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20000, 800000]"
     ]
    }
   ],
   "source": [
    "xgb_preds, xgb_oof, xgb_score, feaNum = xgb_model(train=train, target=target, test=test, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[~data['isDefault'].isnull()].copy()\n",
    "target = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[~data['isDefault'].isnull()].sample(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以下是源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-11\n",
      "读取数据...\n",
      "train.shape (800000, 47)\n",
      "test.shape (200000, 46)\n",
      "初始拼接后： (1000000, 47)\n",
      "n特征处理后： (1000000, 53)\n",
      "count编码后： (1000000, 61)\n",
      "1data.shape (1000000, 53)\n",
      "2_data.shape (1000000, 57)\n",
      "预处理完毕 (1000000, 58)\n",
      "开始特征工程...\n",
      "data.shape (1000000, 74)\n",
      "开始模型训练...\n",
      "num0:mean_encode train.shape (800000, 84) (800000, 84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num1:target_encode train.shape (800000, 89) (800000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:38<00:00, 31.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num2:target_encode train.shape (800000, 109) (800000, 109)\n",
      "输入数据维度： (800000, 104) (800000, 104)\n",
      "Current num of features: 102\n",
      "[0]\ttrain-auc:0.70731\teval-auc:0.69928\n",
      "[100]\ttrain-auc:0.73562\teval-auc:0.72400\n",
      "[200]\ttrain-auc:0.74134\teval-auc:0.72716\n",
      "[300]\ttrain-auc:0.74719\teval-auc:0.73013\n",
      "[400]\ttrain-auc:0.75263\teval-auc:0.73257\n",
      "[500]\ttrain-auc:0.75746\teval-auc:0.73435\n",
      "[600]\ttrain-auc:0.76159\teval-auc:0.73560\n",
      "[700]\ttrain-auc:0.76537\teval-auc:0.73655\n",
      "[800]\ttrain-auc:0.76876\teval-auc:0.73716\n",
      "[900]\ttrain-auc:0.77206\teval-auc:0.73772\n",
      "[1000]\ttrain-auc:0.77526\teval-auc:0.73813\n",
      "[1100]\ttrain-auc:0.77821\teval-auc:0.73852\n",
      "[1200]\ttrain-auc:0.78088\teval-auc:0.73885\n",
      "[1300]\ttrain-auc:0.78346\teval-auc:0.73909\n",
      "[1400]\ttrain-auc:0.78613\teval-auc:0.73926\n",
      "[1500]\ttrain-auc:0.78882\teval-auc:0.73947\n",
      "[1600]\ttrain-auc:0.79134\teval-auc:0.73964\n",
      "[1700]\ttrain-auc:0.79373\teval-auc:0.73979\n",
      "[1800]\ttrain-auc:0.79612\teval-auc:0.73995\n",
      "[1900]\ttrain-auc:0.79847\teval-auc:0.74005\n",
      "[2000]\ttrain-auc:0.80064\teval-auc:0.74013\n",
      "[2100]\ttrain-auc:0.80288\teval-auc:0.74021\n",
      "[2200]\ttrain-auc:0.80516\teval-auc:0.74031\n",
      "[2300]\ttrain-auc:0.80735\teval-auc:0.74036\n",
      "[2400]\ttrain-auc:0.80945\teval-auc:0.74043\n",
      "[2500]\ttrain-auc:0.81164\teval-auc:0.74049\n",
      "[2600]\ttrain-auc:0.81380\teval-auc:0.74057\n",
      "[2700]\ttrain-auc:0.81585\teval-auc:0.74064\n",
      "[2800]\ttrain-auc:0.81788\teval-auc:0.74070\n",
      "[2900]\ttrain-auc:0.82000\teval-auc:0.74069\n",
      "[3000]\ttrain-auc:0.82194\teval-auc:0.74074\n",
      "[3100]\ttrain-auc:0.82397\teval-auc:0.74081\n",
      "[3200]\ttrain-auc:0.82598\teval-auc:0.74086\n",
      "[3300]\ttrain-auc:0.82790\teval-auc:0.74086\n",
      "[3400]\ttrain-auc:0.82983\teval-auc:0.74086\n",
      "[3500]\ttrain-auc:0.83172\teval-auc:0.74086\n",
      "[3600]\ttrain-auc:0.83350\teval-auc:0.74083\n",
      "[3700]\ttrain-auc:0.83540\teval-auc:0.74086\n",
      "[3800]\ttrain-auc:0.83729\teval-auc:0.74086\n",
      "[3900]\ttrain-auc:0.83922\teval-auc:0.74088\n",
      "[4000]\ttrain-auc:0.84105\teval-auc:0.74086\n",
      "[4100]\ttrain-auc:0.84296\teval-auc:0.74083\n",
      "[4200]\ttrain-auc:0.84474\teval-auc:0.74084\n",
      "[4300]\ttrain-auc:0.84647\teval-auc:0.74085\n",
      "[4400]\ttrain-auc:0.84829\teval-auc:0.74079\n",
      "[4500]\ttrain-auc:0.85011\teval-auc:0.74080\n",
      "[4528]\ttrain-auc:0.85060\teval-auc:0.74078\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-44bbb5f6d6ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'输入数据维度：'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m     \u001b[0mxgb_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_oof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaNum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkflod_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0mlgb_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-44bbb5f6d6ea>\u001b[0m in \u001b[0;36mxgb_model\u001b[0;34m(train, target, test, k)\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0mxgb_oof_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mval_pred\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0;31m# oof_probs[test_index] += val_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;31m# 绘制roc曲线\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m         _check_call(_LIB.XGBoosterPredict(self.handle, data.handle,\n\u001b[0m\u001b[1;32m   1490\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_uint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
